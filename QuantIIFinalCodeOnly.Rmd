---
title: "Quant II Final Code Only"
author: "Kelsi Quick"
date: "`r Sys.Date()`"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_knit$set(root.dir = "/Users/kelsiquick/Downloads/QuantII/Final/ESS10-subset")
```


```{r library, include=FALSE}
#load packages
library(readr)
library(optmatch)
library(RItools)
library(ggplot2)
library(cobalt)
library(survey)
library(dplyr)
library(knitr)
library(estimatr)
library(modelsummary)
library(stargazer)
```

**Reading, Subsetting and Cleaning Data**
```{r set wd}
# Set your working directory 

# Read in the dataset
essdata <- read.csv("ESS10-subset.csv")
```

```{r preview data}
# Preview the data
head(essdata)
str(essdata)
```

**Filter to EU Member States**
```{r filter data to EU member states}
# Save a clean copy of the original data
essdata_raw <- essdata

# Define the list of official EU member state codes (as of 2020)
eu_countries <- c("AT", "BE", "BG", "HR", "CY", "CZ", "DE", "DK", "EE", 
                  "ES", "FI", "FR", "GR", "HU", "IE", "IT", "LT", "LU", 
                  "LV", "MT", "NL", "PL", "PT", "RO", "SE", "SI", "SK")

# Filter the dataset to only include EU member states
essdata_eu <- essdata[essdata$cntry %in% eu_countries, ]

# Print which EU countries are actually present in the data
cat("EU countries present in ESS10 dataset:\n")
print(sort(unique(essdata_eu$cntry)))
```

**Create Post-Communist Variable**
```{r creating post communist binary variable}
#Creating post-communist binary variable
post_communist_countries <- c("BG", "CZ", "EE", "HR", "HU", "LT", "SI", "SK")

# Create the binary treatment variable: 1 = Post-Communist, 0 = Non-Post-Communist
essdata_eu$post_communist <- ifelse(essdata_eu$cntry %in% post_communist_countries, 1, 0)

# Quick check 
table(essdata_eu$post_communist)

table(essdata_eu$cntry, essdata_eu$post_communist)

```

**Code Missing Data**
```{r coding missing data}
# Recoding missing data according to ESS codebook 
# Recode 'lrscale' (Political Ideology)
essdata_eu$lrscale[essdata_eu$lrscale %in% c(77, 88, 99)] <- NA

# Recode 'keydec' (Ideal Sovereignty)
essdata_eu$keydec[essdata_eu$keydec %in% c(77, 88, 99)] <- NA

# Recode 'keydecc' (Observed Sovereignty)
essdata_eu$keydecc[essdata_eu$keydecc %in% c(77, 88, 99)] <- NA

# Recode 'gndr' (Gender)
essdata_eu$gndr[essdata_eu$gndr == 9] <- NA

# Recode 'agea' (Age)
essdata_eu$agea[essdata_eu$agea == 999] <- NA

# Recode 'eduyrs' (Years of Education)
essdata_eu$eduyrs[essdata_eu$eduyrs %in% c(77, 88, 99)] <- NA

```

**Examine Missing Data**
```{r checking missing data}
# Check for missing data
colSums(is.na(essdata_eu[, c("lrscale", "keydec", "keydecc", "gndr", "agea", "eduyrs")]))

```

```{r examining data if dropping all NAs }
# Examine what the case would be if all NAs were dropped, and if sample size of PCL and non PCL would still be coomparable
essdata_complete <- essdata_eu[complete.cases(essdata_eu[, c("lrscale", "keydec", "keydecc", "agea", "gndr", "eduyrs")]), ]
table(essdata_complete$post_communist)

```

```{r extreme outlier check}
#Check for extremes/outliers 
summary(essdata_complete$agea)
summary(essdata_complete$eduyrs)
summary(essdata_complete$keydec)   # Ideal sovereignty
summary(essdata_complete$keydecc)  # Observed sovereignty
summary(essdata_complete$lrscale)
summary(essdata_complete$gndr)
```

```{r boxplots of main vars}
#Visualizaing main variable distributions
boxplot(essdata_complete$agea, main = "Age Distribution", ylab = "Age")
boxplot(essdata_complete$eduyrs, main = "Years of Education", ylab = "Years of Education")
boxplot(essdata_complete$keydec, main = "Ideal Sovereignty (keydec)", ylab = "Score 0-10")
boxplot(essdata_complete$keydecc, main = "Observed Sovereignty (keydecc)", ylab = "Score 0-10")
boxplot(essdata_complete$lrscale, main = "Left-Right Ideology (lrscale)", ylab = "Score 0-10")

```

```{r looking into education}
#Looking more into education
table(essdata_complete$eduyrs > 40)
table(essdata_complete$eduyrs > 30)
table(essdata_complete$eduyrs > 25)
```

```{r dropping extreme education values}
# Here I drop extreme education values (over 25 years)
essdata_complete <- essdata_complete[essdata_complete$eduyrs <= 25, ]
# Verifying
summary(essdata_complete$eduyrs)  # Check the new max value is 25
```

**Creating National Sovereignty Deficit Variable**
```{r NSD variable creation}
# Create the National Sovereignty Deficit (NSD) variable
essdata_complete$NSD <- essdata_complete$keydec - essdata_complete$keydecc

# Quick check of the NSD variable
summary(essdata_complete$NSD)

```

```{r NSD visualization}
# view distribution of NSD (raw)
hist(essdata_complete$NSD, 
     main = "Distribution of National Sovereignty Deficit (NSD)", 
     xlab = "NSD (Ideal - Observed Sovereignty)", 
     col = "lightblue", 
     breaks = 20)

```

**Matching Design**
```{r full-matching mahalanobis}

options("optmatch_max_problem_size" = Inf)

#  Create Mahalanobis distance matrix
distance_matrix <- match_on(
  post_communist ~ agea + eduyrs + lrscale, 
  data = essdata_complete, 
  method = "mahalanobis"
)

# Exact matching on gender
exact_gender <- exactMatch(post_communist ~ gndr, data = essdata_complete)

# Apply a global caliper on the Mahalanobis distance
caliper_constraint <- caliper(distance_matrix, width = 1.5)  # Adjust as needed

# Run Full Matching, combining constraints properly
full_match_result <- fullmatch(
  distance_matrix + exact_gender + caliper_constraint
)

# Add matched group labels to dataset
essdata_complete$match_group <- full_match_result

#  Quick check of matched sets
table(essdata_complete$match_group)

```

```{r examining matched sets}
length(unique(essdata_complete$match_group))

sum(is.na(essdata_complete$match_group))  # Number of unmatched respondents

table_sizes <- table(essdata_complete$match_group)
summary(table_sizes)  # Get min, median, mean, and max matched set sizes

hist(table_sizes, 
     main = "Distribution of Matched Set Sizes", 
     xlab = "Set Size", 
     col = "lightblue", 
     breaks = 20)


```

**Balance Test**
```{r assess balance}
# Identify Informative Matched Sets (those with both treated and control units)
informative_sets <- with(essdata_complete, 
                         tapply(post_communist, match_group, function(x) length(unique(x)) > 1))

informative_ids <- names(informative_sets[informative_sets == TRUE])

# Subset the Data to Informative Sets
ess_informative <- subset(essdata_complete, match_group %in% informative_ids)

# Randomly Sample Informative Matched Sets
set.seed(123)  # For reproducibility
sampled_sets <- sample(informative_ids, size = 500) 

# Create Final Sampled Dataset
ess_sample <- subset(ess_informative, match_group %in% sampled_sets)

# Run the Balance Test on the Sampled Data

balanceTest(
  post_communist ~ agea + gndr + eduyrs + lrscale + strata(match_group), 
  data = ess_sample
)

```

**Balance Table Visualizations**
```{r creating covariate balance table visual, echo=TRUE, eval=FALSE }
# balance table for Table X
# balance table with  p-values from balance test output
balance_table <- data.frame(
  Covariate = c("Age", "Gender (Female)", "Education (Years)", "Ideology (LR Scale)"),
  `Treatment Mean` = c(51.1, 1.53, 13.0, 5.39),
  `Control Mean` = c(51.1, 1.51, 13.4, 5.29),
  `SMD` = c(0.00, 0.03, -0.11, 0.05),
  `z-Statistic` = c(0.54, 0.96, 2.10, 0.94),
  `p-Value` = c("0.59", "0.34", "0.04 *", "0.35")  # p-Value for education flagged as significant
)

# Display the table
kable(balance_table, 
      caption = "Table X. Covariate Balance After Matching (500 Informative Sets)", 
      digits = 2, 
      align = "lccccc")
```

```{r overall balance table visual, echo=TRUE, eval=FALSE}
# creating the visual
# Create overall balance test table
overall_balance_table <- data.frame(
  Test = c("Unadjusted", "Adjusted"),
  `Chi-Square` = c(5.53, 6.66),
  `df` = c(4, 4),
  `p-Value` = c("0.237", "0.155")
)

kable(overall_balance_table, 
      caption = "Table Y. Overall Balance Test (Chi-Square)", 
      digits = 3, 
      align = "lccc")
```

**False Positive Rate**
```{r #10, permutations and false positive rate}

set.seed(12345) #for reproducibility 

# Create weights from matched groups
match_counts <- table(essdata_complete$match_group, essdata_complete$post_communist)
treated_counts <- match_counts[, "1"]
control_counts <- match_counts[, "0"]

# Assign weights based on match group sizes
essdata_complete$weight <- with(essdata_complete, ifelse(
  post_communist == 1,
  1 / treated_counts[match_group],
  1 / control_counts[match_group]
))

# Function to compute p-value for each simulation (using OLS regression)
compute_p_value <- function(data) {
  model <- lm(NSD ~ post_communist, data = data, weights = weight)
  p_val <- summary(model)$coefficients["post_communist", "Pr(>|t|)"] #extracts p value for each estimate
  return(p_val)
}

# Permute treatment assignment within matched groups to preserve matching structure
# simulates null distribution under assumption of no effect
permute_within_groups <- function(data) {
  permuted_data <- data
  permuted_data$post_communist <- unlist(
    tapply(permuted_data$post_communist, permuted_data$match_group, sample)
  )
  return(permuted_data)
}

# Run simulations to estimate false positive rate
n_simulations <- 1000
p_values <- replicate(n_simulations, {
  null_data <- permute_within_groups(essdata_complete)
  compute_p_value(null_data)
})

#  Calculate and report false positive rate at alpha = 0.05
false_positive_rate <- mean(p_values < 0.05) #calculates how often the p-value was below 0.05, thereby counting how often the test registered a significant effect when there was none
cat("Estimated False Positive Rate (Type I Error):", false_positive_rate, "\n")

# Optional: Visualize p-value distribution
hist(p_values, breaks = 30, main = "P-Value Distribution Under Null", xlab = "P-Value")


```


**Power**
```{r #10, power}

set.seed(12345)

# Define Power Simulation Function
power_function <- function(simulations, treatment, outcome, block, effect_size) {
  p_values <- replicate(simulations, {
    # Reshuffle treatment assignment within matched groups
    permuted_treatment <- unlist(tapply(treatment, block, sample))
    
    # Simulate new outcomes under the assumed true effect
    simulated_outcome <- outcome + permuted_treatment * effect_size
    
    # Run weighted OLS regression on simulated data
    model <- lm(simulated_outcome ~ permuted_treatment, weights = essdata_complete$weight)
    
    # Extract p-value for the treatment effect
    p_val <- summary(model)$coefficients["permuted_treatment", "Pr(>|t|)"]
    return(p_val)
  })
  
  return(p_values)
}

# Simulate Power for a Range of Effect Sizes
effect_sizes <- c(0, 0.5, 1, 2, 3)  

power_estimates <- sapply(effect_sizes, function(effect) {
  p_vals <- power_function(
    simulations = 1000,
    treatment = essdata_complete$post_communist,
    outcome = essdata_complete$NSD,
    block = essdata_complete$match_group,
    effect_size = effect
  )
  mean(p_vals < 0.05)  # Power is the proportion of p-values below 0.05
})

#  Plot Power Curve
plot(effect_sizes, power_estimates, type = "b", pch = 19,
     main = "Power Curve",
     xlab = "True Treatment Effect Size",
     ylab = "Estimated Power")

```

```{r #10, saving power plot}
power_plot <- plot(effect_sizes, power_estimates, type = "b", pch = 19,
     main = "Power Curve",
     xlab = "True Treatment Effect Size",
     ylab = "Estimated Power")

```


```{r power-plot, echo=FALSE, fig.cap="Power Curve for Hypothesis Test"}
plot(effect_sizes, power_estimates, type = "b", pch = 19,
     main = "Figure 1: Power Curve for Hypothesis Test",
     xlab = "True Treatment Effect Size",
     ylab = "Estimated Power")
```


**Bias and MSE**
```{r #13 assessing bias and mse}

set.seed(12345)

# Define True Treatment Effect 
true_ATE <- 1.00


# Simulation Function to Estimate Treatment Effects
simulate_estimator <- function(data, true_effect) {
  # Shuffle treatment assignment within matched sets to simulate randomness
  permuted_treatment <- unlist(tapply(data$post_communist, data$match_group, sample))

  # Simulate outcomes under known true effect
  simulated_outcome <- data$NSD + permuted_treatment * true_effect

  # Estimate treatment effect using weighted OLS
  model <- lm(simulated_outcome ~ permuted_treatment, weights = data$weight)
  estimated_effect <- coef(model)["permuted_treatment"]
  
  return(estimated_effect)
}

# Run Simulations
n_simulations <- 1000
estimated_effects <- replicate(n_simulations, simulate_estimator(essdata_complete, true_ATE))

# Calculate Bias, Variance, and MSE
estimated_mean <- mean(estimated_effects)
bias <- abs(estimated_mean - true_ATE)
variance <- var(estimated_effects)
mse <- mean((estimated_effects - true_ATE)^2)

# Output Results
cat("Bias:", bias, "\n")
cat("Variance:", variance, "\n")
cat("MSE:", mse, "\n")


```

**Regression Table**
```{r #14 final table, reg weighted}
# Calculate weights based on matched set sizes; I do this because with so many matched sets, R crashes when running a regression with matched groups as a factor

essdata_complete <- essdata_complete %>%
  group_by(match_group) %>%
  mutate(weight = 1 / n())

# Then run the weighted regression
reg_weighted <- lm(NSD ~ post_communist, data = essdata_complete, weights = weight)

# View results
summary(reg_weighted)


```

```{r  #14 stargazer output}
stargazer(reg_weighted, 
          type = "latex", 
          title = "OLS Regression Results", 
          dep.var.labels = "National Sovereignty Deficit", 
          covariate.labels = c("Post-Communist Country"), 
          no.space = TRUE, 
          digits = 3)
```



## For in-project visualizations: 

```{r balance_table, echo=FALSE, message=FALSE, warning=FALSE}

# balance table with  p-values from balance test output
balance_table <- data.frame(
  Covariate = c("Age", "Gender (Female)", "Education (Years)", "Ideology (LR Scale)"),
  `Treatment Mean` = c(51.1, 1.53, 13.0, 5.39),
  `Control Mean` = c(51.1, 1.51, 13.4, 5.29),
  `SMD` = c(0.00, 0.03, -0.11, 0.05),
  `z-Statistic` = c(0.54, 0.96, 2.10, 0.94),
  `p-Value` = c("0.59", "0.34", "0.04 *", "0.35")  # p-Value for education flagged as significant
)

# Display the table
kable(balance_table, 
      caption = "Table X. Covariate Balance After Matching (500 Informative Sets)", 
      digits = 2, 
      align = "lccccc")

```

```{r overall balance table, echo=FALSE, message=FALSE, warning=FALSE}

# Create overall balance test table
overall_balance_table <- data.frame(
  Test = c("Unadjusted", "Adjusted"),
  `Chi-Square` = c(5.53, 6.66),
  `df` = c(4, 4),
  `p-Value` = c("0.237", "0.155")
)

kable(overall_balance_table, 
      caption = "Table Y. Overall Balance Test (Chi-Square)", 
      digits = 3, 
      align = "lccc")

```

```{r power-plot, echo=FALSE, fig.cap="Power Curve for Hypothesis Test"}
plot(effect_sizes, power_estimates, type = "b", pch = 19,
     main = "Figure 1: Power Curve for Hypothesis Test",
     xlab = "True Treatment Effect Size",
     ylab = "Estimated Power")
```

```{r, results='asis', echo=FALSE}
# Regression Table
library(stargazer)
stargazer(reg_weighted, 
          type = "latex", 
          title = "OLS Regression Results", 
          dep.var.labels = "National Sovereignty Deficit", 
          covariate.labels = c("Post-Communist Country"), 
          no.space = TRUE, 
          digits = 3)
```


